---
title: "ch-6-comparing-groups-tests"
author: "Sonya Hua"
date: "September 8, 2017"
output: rmarkdown::github_document
---

```{r setup, include=FALSE}
library(knitr)
knitr::opts_chunk$set(echo = TRUE)

# set global display parameters
knitr::opts_chunk$set(fig.width=8, fig.height=5, echo = TRUE, fig.align="center") 
```

"It looks different but is it really different?" The answer involves our first [inferential statistical](https://statistics.laerd.com/statistical-guides/descriptive-inferential-statistics.php) procedures: *chi-square, t-tests, and ANOVA*. 

It's all about estimating parameters and testing hypotheses. Before applying any stat test or model, it's impotant to examine the data and check for 1) missing values 2) outliers 3) Skewness 4) Normal Distributions. Since more tests assume a normal distribution or some other smooth continuous distribution.

###6.1 Data for Comparing Groups
```{r}
load("C:/Users/sonya/Documents/git/r-for-marketing-research-and-analytics/segdf-Rintro-Ch5.RData")
summary(seg.df)
```

###6.2 Chi-Square Test: Testing differences between Group Frequencies

Most of the work in marketing analytics and marketing research involves summarizing the differences between groups using group averages and cross tabs. However, best practice is to be able to use *statistical tests* to determine whether the differences are real or might instead be due to noise in the data. 

One of the simplest tests is the *[chi-square test](https://onlinecourses.science.psu.edu/statprogram/node/158)*, which is used with frequency count tables. *A chi-square test determines whether the frequencies in cells are significantly different from what one would expect on the basis of their total counts if data was randomly sampled from a large population where groups are equally distributed given a sample size. For example, knowing var A will not help inform var B. There are not related or are independent of each other 

H0: Variable A and Variable B are independent. 
Ha: Variable A and Variable B are not independent (dependent)

`chisq.test()` operates on a `table()`

```{r}

# Chi-square test # 1
example.data <- rep(c(1:4), times= c(25,25,25,20))
tmp.tab <- table(example.data)
tmp.tab

chisq.test(tmp.tab)
```
*Observe*: 

* we generated 95 observations of 1:4, compile those in a table, and then test that table for *chi-square independence*.
* Test evaluates the likelihood of seeing such a result under the null hypothesis that the data is randomly sampled from a population where the values 1 to 4 are equally distributed, given a marginal count of N=95 observations.
* The p-value of 0.852: Under null hypothesis, there is an 85.2% chance of seeing a data set with differences similar to or greater than those in our table.
* Under the asssumptions of the chi-square test, our table does not suggest significant differences in frequency between the 4 cells
* The data shows no evidence that the groups in the population are of unequal size if it was randomly sampled from an equal distribution
* 1:4 are indepndent of each other. 
```{r}
tmp.tab <- table(rep(c(1:4), times=c(25,25,25,10)))
tmp.tab

chisq.test(tmp.tab)
```

*Observe*: 

* p=0.047: We can reject the null hypothesis with 95% confidence that there is no difference between the cells 
* The data in this sample suggests that the distribution of the values 1 to 4 is likely to be unequal in the *larger population*, assuming the data is randomly sampled. 

If we have a smaller sample, we would not get the same results even if the relative proportions of customers in each group are the same. Significance tests are sensitive to both the observed difference and sample size: 

```{r}
tmp.tab <-tmp.tab/5
tmp.tab

chisq.test(tmp.tab)
```
*Observe*:
 
 * The results are not significant and there is no evidence of a real difference in group sizes even though the proportion of people in group 4 is the same as in larger sample above where results were significant. 
 
That's one of the cautions about statistical significance testing: *it's dependent on sample size as well as on the real effect*

Another example, let's return to our simulated segment data (N=300 obs). 

##### Are the segment sizes significantly different from one another?

Assuming that the 300 customers are *random sample of a larger population*, we can use the chi-square test. We'll combine `chisq.test()` and `table()` into one command: 
```{r}
table(seg.df$Segment)
chisq.test(table(seg.df$Segment))
```
*Observe*

* With p=0.0006, there are significant differences in segment size
* Our sample does not support the hypothesis that there is an idenditcal number of custommers in each segment.

##### Is subscription status independent from home ownership? 

In other words, are respondents just as likely to subscribe or not subscribe,  regardless of home ownership status? Are customers just as likely to own a home or not, independent of subscription status? The null hypothesis is that home ownership and subscription status is independent i.e. that the counts in the cells are as one might expect from marginal proportions. 

There's 2 optionos for chi-square test:

1) For 2x2 contingency tables, chi-square test defaults to using *Yates' correction* which adjusts the chi-square statistic since data is not continuous (comes from a lumpy binomial distribution). To turn this off, use `correct=F` option.

2) Chi-square tests can calculate confidence intervals based on simulation, whereby it compares the observed table to thousands of simulated tables wit hteh same marginal counts. The p-value indicates the proportion of those simulations with differences between the cell counts nad marginal proportions at least as large as the ones in the observed table using the `sim=T` and `B=SIMULATIONS` arguments

```{r}
table(seg.df$subscribe, seg.df$ownHome)


# Using's Yates' correction
chisq.test(table(seg.df$subscribe, seg.df$ownHome))

# Using traditional values without Yates' correction
chisq.test(table(seg.df$subscribe, seg.df$ownHome), correct=F)

# Using simulation method of 10000 trials
chisq.test(table(seg.df$subscribe, seg.df$ownHome), sim=T, B=10000)


```
*Observe*

* Based on high p-value, we fail to reject null hypothesis and conclude that the factors are unrelated. Home ownership is independent of subscription status in our data. There is no relationship between subscriiption rate and home ownership. The factors are independent. 

### 6.3 Testing Observed Proportions: `binom.test()`

**Binomial variables** are variables that have only 2 types of values ("Y/N" "0,1"). 

For example, Chris took a walk in Manhattan and observed 12 groups of Seattle fans and 8 groups of Denver fans. Assuming the observations are a random sample of a binomial value (either Seattle or Denver fans). Is the observed value of 60% Seattle fans significantly different from equal representation (which would be 50% each)? 

We use `binom.test(successes, trials, probability)` to test what's the likelihood of randomly observing 12 groups out of 20 in one direction, if the true likelhood is 50%? 

```{r}
binom.test(12,20,p=0.5)
```
*Observe*: 

* The 95% CI is 36-81% which includes the null hypothesis value of 50% probability. 
* We conclude that observing 60% seattle fans in a sample of 20 does not conclusively demonstate that there are more Seattle fans in the larger group of fans roaming New York. 
* The p-value=0.5034 is not significant - we fail to support the idea that the results are different from the null hypothesis

####6.4.1 Interpreting Confidence Intervals

The definition of a 95% CI: *It's the range of possible sample estimates that we would expect to see 95% of the time if we repeatedly estimate the  statistic using random samples of the same sample size under the assumption that the true value in an infinite or very large population is the same as our current estimate*

It's the best guess of possible answers we would expect with repeated random sampling. 

When the CI excludes null hypothesis, the result is statistically significant. 

CI's DO NOT express our degree of confidence in our results since they don't reflect the confidence elvel in the assumptinos made. 

CI's are often misunderstood to imply that "the true value lies in the CI range" when it's the other way around "if the true value is what we obtained then we would expect additional esitmates to fall within this CI 95% of the time with random sampling."

The CI is about sample estimates, not about the true value of a population. 

Before interpreting a result, make surue it's statitically significant. If not, then the evidence for our result is weak and we should not intepret it. Best pracice is to chart the confifdence intervals when available and always report out on confidence intervals for a more complete and accurate description to stakeholders. 

`confint()` determines the CIs for a statistical model

#### What's the probability we would observe 8:12 Seattle fans out of 20, if the true rate is 50%?

Use the *density estimate* for a binomial distribution across the range of interest and sum the point probabilities:
```{r}
sum(dbinom(8:12, 20, 0.5))
```
*Observe* If we observe 20 fans and the true split is 50%, there's a 73.7% chance that would would observe between 8 to 12 fans. 


An *exact* binomial test may be too conservative (wide CI) in its estimation of CI's. Another method is to use the *[agresti-coull](http://www.stat.ufl.edu/~aa/articles/agresti_coull_1998.pdf)* method to get a slightly smaller CI but still includes 50%. Use `binom.confint(method="ac")`
```{r}
library(binom)
binom.confint(12, 20, method="ac")
```
*Observe* The CI bound using approximate (0.39 to 0.78) is smaller compared to exact binomial test (0.36 to 0.81)


##### What if we observed 120 out of 200 people to be Seattle fans? (The same proportion as before but in a larger sample)

```{r}
binom.test(120,200,.5)
```
*Observe*:

* The CI no longer includes 50%. The p-value < 0.05, indicating there is a statistically signifciant difference. 

#### Among the 20 groups, 0 groups had a mixture of Seattle and Denver fans based on their team clothing. What's the most likely proportion of groups that comprise of mixed fans?

We need to use the *Agresti-Coull* method because exact tests have no confidence intervals for 0% or 100% observations:
```{r}
binom.confint(0,20, method="ac")
```
*Observe*: The negative bound may be ignored as an artifact. We conclude that althouogh Chris observed 0 cases, the occurrence of mixed fandom groups is likely to be between 0 to 19% of the time.


The `binom` package also computes several other varients of the binomial test including a Bayesian version. 

### 6.4 T-test: Testing Group Means

A *[t-test](http://www.stat.columbia.edu/~martin/W2024/R2.pdf)* compares the mean of one sample against mean of another sample or against a specific valie i.e. 0. It compares means for exactly 2 data sets. 


#### Is the household income different among those who own a home and those who do not?

Let's check for normality before doing a t-test:
```{r fig.width=12}

# Fix the levels first

levels(seg.df$ownHome) <- c(levels(seg.df$ownHome), "ownNo")
seg.df$ownHome[is.na(seg.df$ownHome)] <- "ownNo"
summary(seg.df$ownHome)

seg.df$ownHome <- droplevels(seg.df$ownHome)
levels(seg.df$ownHome) <- c("ownYes","ownNo")
summary(seg.df$ownHome)
```

```{r fig.width=12}
par(mfrow=c(1,3))
hist(seg.df$income)
with(seg.df, hist(income[ownHome=="ownYes"]))
with(seg.df, hist(income[ownHome=="ownNo"]))

```

```{r fig.height=4}
# boxplot

#bwplot(ownHome ~ income, data=seg.df, horizontal = T, xlab="Income $", layout=c(1,2))
```
*Observe* Based on the histograms and boxplots, income is ~ normally distributed. 

Test whether home ownership overall is related to differences in income, across all segments, using `t.test(formula,data)` where `income` is the y var and `ownHome` is the x var. 

```{r}
t.test(income ~ ownHome, data=seg.df)
```
*Observe* 

*The 95% CI does not include 0, so we can conclude there is significant difference in income between home ownership. 
*The data suggests that people who own their houses have a higher income. 
*We have 95% confidence that the group difference is between \$3007 and \$12,080.
*The mean income for renters is \$47K while homeowners $55K

#### Is there a difference income between homeownrship within the Travelers segment?

We use the filter `data=subset(data, condition)` to select just Travelers and repeat the test:
```{r}
t.test(income~ ownHome, data=subset(seg.df, Segment=="Travelers"))
```
*Observe*

* The CI of -$8,508 to $11,107 include 0 which means there is not a significant difference in mean income among those Travelers in our data who own homes and who don't. 
* P-Value = 0.7916 deems not significant
* We noticed earlier that the first t-test is significant across all segments, but this test is not significant. This suggests that any significant difference must lie largely outside the "Travelers" segment

###6.5 ANOVA: Testing Multiple Group Means (vs. t-test which tests 2 groups)

ANOVA compares means of multiple groups by comparing the degree to which groups differ as measured by variance in their means from one another, relative to the variance of abervations around each mean within each group. It tests for difference among multiple means with the assumption that the groups have similar variance. 

*One-way ANOVA: Includes 1 factor
*Two-way ANOVA: Includes 2 factors

`aov(formula,data)`: basic command to set up the ANOVA model
`anova(model)`: to display standard ANOVA summary from `aov()`


##### Which factors are related to differences in mean income? Is income related to home ownership, to segment membership, or both? 

1) We run `aov(income ~ ownHome)` and assign the `aov()` model to an object so we can use it in our next step
2) `anova()` on the aov model object

```{r}
seg.aov.own <- aov(income ~ ownHome, data=seg.df)
anova(seg.aov.own)
```
*Observe*:

* There's significant variation between home ownership status and income (p-value < 0.05)

##### Is there a difference in income by segments?
```{r}

aov.inc.segments <- aov(income ~ Segment, data=seg.df)
anova(aov.inc.segments)
```
*Observe*:

* Income varies significantly by segment. 

##### If income varies by both home ownership and segment, does that mean that a more complete model should include both? 

We add both factors into the two-way ANOVA model to test this:
```{r}
anova(aov(income ~ Segment + ownHome, data=seg.df))
```
*Observe*: Results indicate that when we try to explain income differences by both Segment and home ownership, segment is a significant predictor, but not home ownership. Why? Because segment and homeownership are dependent, and the variation is captured sufficiently by segment membership alone. We can test this further using chi-square test to validate if this is true.

```{r}
table(seg.df$ownHome, seg.df$Segment)
chisq.test(table(seg.df$ownHome, seg.df$Segment))
```
*Observe* Yes, there is a significant difference between Segments and Home ownership. 

##### Could it be that home ownership is related to income in some segments but not in others?

This would be represented in our model by an *interaction effect*. In a model, 

"+" indicates vars should be modeled for main effects only.
":" model for interaction effect
"*" model for both main effect and interaction

We'll test main effects and interaction of home ownership and segment
```{r}
anova(aov(income ~ Segment * ownHome, data=seg.df))
```
*Observe* 

* Segment is a significant predictor while the rest are not. Segment membership is again the best predictor on its own. 

#### 6.5.1 Model Comparison in ANOVA

Another capability of `anova()` command is to compare 2+ models so we can analyze which model performs better in fitting the data according to RSS (Residual Sum of Squares).  NOTE: model comparison performed by `anova()` onlyl makes sense for nested models where we can perform likelihood comparisons. Other methods should be used such as the AIC and BIC criterion.

##### Which model has a better fit? ANOVA model with segment alone vs. the model with both segment + homeownership? 

```{r}
anova(aov(income ~ Segment, data=seg.df),
      aov(income ~ Segment + ownHome, data=seg.df))
```
*Observe*:

* Model 2 is not significantly different in overall fit from Model 1. 
* We fail to reject the null hypothesis of no difference in the 2nd model 

#### 6.5.2 Visualizing Group CI's 

Best practice is to visualize the results of an ANOVA by plotting confidence intervals for the group means. This tells us whether the differences are substantial in magnitude or not.  

`glht(model)` is a general linear hypothesi stest part of the `multcomp` package (multiple comparison)
```{r}
library(multcomp)
seg.aov <- aov(income ~ Segment, data=seg.df)
glht(seg.aov)
```
*Observe*: The intercept become the Moving Up segment and all results are relative to the intercept (see the positive/negative numbers)

This may be confusing to understand, so let's remove the intercept by adding "-1" to the model formula.
```{r}

seg.aov <- aov(income ~ -1 + Segment, data=seg.df)
glht(seg.aov)
```
*Observe* Mean value for each segment is provided. 
```{r}
par(mar=c(6,10,2,2))
plot(glht(seg.aov),
     xlab="Income", main="Average Income by Segment (95% CI)")
```
*Observe*: 

* The average income of Urban Hip segment is substantially lower than the other three groups
* Confidence intervals for income by segment is provided. 
* We see Urban Hip segment has a larger CI than other segments. Suburb Mix has a smaller CI. 

####6.5.3 Stepwise Modeling: Variable Selection for ANOVA

With stepwise modeling, we can aotmate the iterative process of bulding models by adding/removing variables from the model based on some threshold/improvement criterion. 

* Backward stepwise: starting with a larger set of vars and progressing cutting them. This is the default direction of `step()`
* Forward stepwise: adding variables

`step()` uses the AIC to compare models on the basis of overall fit and model complexity. Use `response ~ .` to model all main effects in the model where "." is short for "all other variables except the response var. By default, this model tests all main effects without interactions. To test higher order effects (i.e. quadratic), use superscript notation i.e. "`.^2`" for two-way interactions, but it's usually good to avoid such interaction modeling. 

```{r}
seg.aov.step <- step(aov(income ~., data=seg.df))
```
*Observe* Stepwise modeling included all 6 vars at first, went through several steps of removing vars, and concluded with the "best" model as `income ~ Segment`.

We can exampine the result of stepwise modeling using `anova()` on the model object
```{r}
anova(seg.aov.step)
```

In cases where there's dozens, hundreds or thousands of vars, it's better to use other procedures like lasso, random forect, or a machine learning algorithm (SGD, Decision Trees, Regression etc.)

### 6.6 Bayesian ANOVA

It's preferred to consider Bayesian Analyses instead of traditional, frequentist statistics whenever possible.

Upsides:
* It's a more direct way to tackle the questions we usually want to know such as "Is this hypothesis likely to be true, given the data?", "How much confidence do I have?", "What are the most likely values?", "Given this data, how likely is the difference?"
* There is no null hypothesis
* More directly addresses confidence in models for the data we actually have
* Hierarchical methods are more flexibly modeled in a Bayesian framework

Downsides:

* There are fewer Bayesian teachers, resources, and practitioners.
* Many Bayesian references are dense with formulas
* There are ambiguities
* Avail software packages are designed to make frequentist models easy to run. It's not so easy for Bayesian.

####6.6.2 Basics of Bayesian ANOVA

Bayesian packages:

* `[MCMCpack](http://mcmcpack.berkeley.edu/)` (Markov Chain Monte Carlo) is a robust, fast, powerful Bayesian kit. Contains functions to perform Bayesian inference using posterior simulation for a number of statistical models include *linear regression (with Gaussian errors), Quinn's dynamic ecological inference model, Wakefield's hierarchial ecological inference model, a probit model, a logistic regression model, a one-dimensional item response theory model, a K-dimensional item response theory model, a robust k-dimensional item response theory model, a Normal theory factor analysis model, a mixed response factor analysis model, an ordinal item response theory model, a Poisson regression, a Poisson changepoint model, a tobit regression, a multinomial logit model, an SVD regression model, and an ordered probit model*

* `[BayesFactor](http://bayesfactorpcl.r-forge.r-project.org/)`  enables the computation of Bayes factors in standard designs, such as one- and two- sample designs, ANOVA designs, and regression. Another [good read here](https://thewinnower.com/papers/using-bayes-factors-to-get-the-most-out-of-linear-regression-a-practical-guide-using-r)

A common way to estimate a Bayesian model is to do repeated trial assessments of how well a model fits the data. Common Bayesian models select random values for model parameters (such as the mean) and retains the parameter based on the likelihood that it fits the data and prior expectation (an estimated starting point). This process is repeated thousands/millions of times. The retained estimates are the *draws* from the posterior distribution for the parameters. The final estimated distribution of each estimate is the posterior distribution. In the end, we get a large sample of possible parameters and their likelihoods i.e. an outline of the most likely parameters for a given model. 

We'll use `lmBF(formula, data)` to specify our ANOVA model as a Bayesian linear model for `income` modeled by `Segment`. We'll set a pseudorandom number seed b/c this function will take *draws* from the *posterior distribution*. Before we directly interpet this model though, it's best practice to have a sense that it is an adequate model. We'll compare it to the alternative model we considered earlier `income ~ Segment + ownHome`. We should interpet whichever model fits the data better.

Model comparison in `BayesFactor` is performed by usnig the '/' operator to find the ratio of the models' Bayes Factor.
```{r}
#install.packages("MCMCpack")
#install.packages("BayesFactor")

library(MCMCpack)
library(BayesFactor)

# BFManual() for Manual to BayesFactor

# Set a psedurandom number seed to take draws from a posterior distrib.
set.seed(96761)

# First Bayes ANOVA Model
seg.bf1 <- lmBF(income ~ Segment, data=seg.df)

# 2nd Bayes ANOVA Model
seg.bf2 <- lmBF(income ~ Segment + ownHome, data=seg.df)

# Model Comparison based on Bayes Factor ratio
seg.bf1 / seg.bf2
```
*Observe*:

* The Bayes Factor ratio for Model 1 is ~6.58. Model 1 is the preferable model by a factor of 6.58. 

`posterior(model, index, iterations=)` to find the model parameters, and their *credible ranges* based on *n* draws/iterations and # of numberators (index)

The draws from this posterior distribution are called a *chain* since they're estimated by a **[Markov chain process](http://setosa.io/ev/markov-chains/)**. This is a [good video](https://www.khanacademy.org/computing/computer-science/informationtheory/moderninfotheory/v/markov_chains) on Markov chain process and here's another [article](http://techeffigytutorials.blogspot.com/2015/01/markov-chains-explained.html). 

```{r}
(seg.bf.chain <- posterior(seg.bf1, 1, iterations=10000))
```
*Observe* Each row represents a draw, and columns for the estimates per segment. We can't yet interpret these estimates until we check whether the draws *converged* to stable values so that the estimates a reliably interpretable. 

To check for convergence of draws, call `plot()` on the chain objeect's parameters columns that we care about. In this case, we care about all parameters except the last column. 

```{r}
plot(seg.bf.chain[,1:6])
```
*Observe*:

* On the left are the estimated parameter values plotted against draw sequence (x-axis). These form a fat, straight line, which means the estimates varied around a stable central point; thus, they converged. If they had not converged, the plot would show erratic variations up/down, or would spread out increasingly rather than a straight line.
* On the right are density plots of the values. The density shape is ~ normal, which matches the assumption of the regression model. * The charts confirm the model achieved stable estimates and converged

####6.6.3 Inspecting the Posterior Draws

We can now examine the parameters as expressed in our posterior draw chain by using `summary()` on the chain.

Interpretation Guidelines:

* The 1st section (Empirical mean/sd for each var) gives central tendency estimates for the 10K draws of each of the parameters in the chain. The model estimates an overall mu that is the bet guess for hte population mean regardless of segment effects, and then estimates each segment as a deviation from that mean, which isn't as useful as reporting out on actual observed estimates for the mean of each segment rather than its deviation. 

* The 2nd section (Quantiles) reports the actual observed quantiles for each of the parameters
```{r}
summary(seg.bf.chain)
```
*Observe*: The 1st section provides deviation from mu for each of the segments. 

To estimate the direct values for each segment, we'll add the population mu to the deviations for each segment. However, we can't simply add mu to the deviations since the deviations are aggregated, average deviations. The best estimates of segment totals are found within each draw, thus we need to compute segment values at that level, then summarize those estimates. 

```{r}
# Examine the chain object
head(seg.bf.chain)

#By indexing the chain, the confirm this is a matrix:
seg.bf.chain[1:4,1:5] # Select 4 rows, 5 columns

```
We're going to add mu to each segment columns (deviations from mu) to arrive at total estimates per segment. Perform matrix addition to find within-draw estimates for each row. Add column 1, the population estimate, to each of the other columns 2-5. Test this first on rows 1:4 only
```{r}

seg.bf.chain[1:4,2:5] + seg.bf.chain[1:4, 1]  
```

It works! Now we compute that total for all rows and assign the results to a new chain object and resummarize:

```{r}
seg.bf.chain.total <- seg.bf.chain[,2:5] + seg.bf.chain[,1]
summary(seg.bf.chain.total)
```
We can also manually pull [credible intervals](https://www.r-bloggers.com/confidence-vs-credibility-intervals/). For example, by applying `quantile()` with the probabilities that we want to the columns, we get 95% credible interval.  Transposing the results with `t()` provides more readable results.
```{r}
(seg.bf.95ci <- t(apply(seg.bf.chain.total, 2, quantile, pr=c(0.025, 0.5, 0.975))))

```
*Observe* 

*These values are the beste istimates of the the 95% credible range for the estimates of mean income as modeled by segment, under the assumptions of our model. 
*A [Bayesian statistician](https://arxiv.org/pdf/1411.5018.pdf) inteprets results as “given our observed data, there is a 95% probability that the true value of mu falls within this credible region”
* A[ Frequentist statistician](https://www.r-bloggers.com/confidence-vs-credibility-intervals/) interprets “there is a 95% probability that when I compute a confidence interval from data of this sort, the true value of mu will fall within it”.

##### Confidenve vs. Credible Intervals

The Bayesian approach fixes the credible region, and guarantees **95% of possible values ** of will fall within it. The frequentist approach fixes the parameter, and guarantees that **95% of possible confidence intervals** will contain it.

#### 6.6.4 Plotting Bayesian Credible Intervals

We can plot credible intervals using `ggplot2` to plot error bars. Works best with data frames, so we need to coerce our credible interval into a df and add a column for segment names. We plot the chart in 3 steps:

1a) coerce credible intervals into a df

1b) We add elements corresponding to the values of the segment quartiles in the df.

2) We add points for the y values (the estimated median in this case), and add the 2.5% and 97.5% quartiles as "error bars" (associated with `ymax` and `ymin`). 

3) Draw the plot object, adding a title, flipping the plot coordinates so segments are on the left


`ggplot()` initializes a ggplot object. It can be used to declare the input data frame for a graphic and to specify the set of plot aesthetics intended to be common throughout all subsequent layers unless specifically overridden. Note: `aes` are aesthetic mappings that describe  how variables in the data are mapped to visual properties (aesthetics) of geoms. 
```{r}
library(ggplot2)

#1a) coerce CrI into a df
(seg.bf.df <- data.frame(seg.bf.95ci))

```
```{r}

#1b) Add elements to df
(seg.bf.df$Segment <- rownames(seg.bf.df))
(p <- ggplot(seg.bf.df, aes(x=Segment, y=X50., ymax=X97.5., ymin=X2.5.)))

```
`geom_point` : The point geom is used to create scatterplots
`geom_errorbar`: Various ways of representing a vertical interval defined by x, ymin and ymax. Each case draws a single graphical object.
```{r}
#2) add points for the y-vals and error bars which are associated with ymax and ymin
(p <- p + geom_point(size=4) + geom_errorbar(width=0.2) + ylab("Income"))
```
```{r}
# 3) PLot object while adding a title and flipping coordinates
p + ggtitle("95% CI for Mean Income by Segment") + coord_flip()
```
Notice above plot is similar to what we get with frequentist stats.
```{r}
par(mar=c(6,10,2,2))
plot(glht(seg.aov),
     xlab="Income", main="Average Income by Segment (95% CI)")
```

