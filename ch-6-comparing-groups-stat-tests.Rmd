---
title: "ch-6-comparing-groups-tests"
author: "Sonya Hua"
date: "September 8, 2017"
output: rmarkdown::github_document
---

```{r setup, include=FALSE}
library(knitr)
knitr::opts_chunk$set(echo = TRUE)

# set global display parameters
knitr::opts_chunk$set(fig.width=8, fig.height=5, echo = TRUE, fig.align="center") 
```

"It looks different but is it really different?" The answer involves our first [inferential statistical](https://statistics.laerd.com/statistical-guides/descriptive-inferential-statistics.php) procedures: *chi-square, t-tests, and ANOVA*. 

It's all about estimating parameters and testing hypotheses. Before applying any stat test or model, it's impotant to examine the data and check for 1) missing values 2) outliers 3) Skewness 4) Normal Distributions. Since more tests assume a normal distribution or some other smooth continuous distribution.

###6.1 Data for Comparing Groups
```{r}
load("C:/Users/sonya/Documents/git/r-for-marketing-research-and-analytics/segdf-Rintro-Ch5.RData")
summary(seg.df)
```

###6.2 Chi-Square Test: Testing differences between Group Frequencies

Most of the work in marketing analytics and marketing research involves summarizing the differences between groups using group averages and cross tabs. However, best practice is to be able to use *statistical tests* to determine whether the differences are real or might instead be due to noise in the data. 

One of the simplest tests is the *[chi-square test](https://onlinecourses.science.psu.edu/statprogram/node/158)*, which is used with frequency count tables. *A chi-square test determines whether the frequencies in cells are significantly different from what one would expect on the basis of their total counts if data was randomly sampled from a large population where groups are equally distributed given a sample size. For example, knowing var A will not help inform var B. There are not related or are independent of each other 

H0: Variable A and Variable B are independent. 
Ha: Variable A and Variable B are not independent (dependent)

`chisq.test()` operates on a `table()`

```{r}

# Chi-square test # 1
example.data <- rep(c(1:4), times= c(25,25,25,20))
tmp.tab <- table(example.data)
tmp.tab

chisq.test(tmp.tab)
```
*Observe*: 

* we generated 95 observations of 1:4, compile those in a table, and then test that table for *chi-square independence*.
* Test evaluates the likelihood of seeing such a result under the null hypothesis that the data is randomly sampled from a population where the values 1 to 4 are equally distributed, given a marginal count of N=95 observations.
* The p-value of 0.852: Under null hypothesis, there is an 85.2% chance of seeing a data set with differences similar to or greater than those in our table.
* Under the asssumptions of the chi-square test, our table does not suggest significant differences in frequency between the 4 cells
* The data shows no evidence that the groups in the population are of unequal size if it was randomly sampled from an equal distribution
* 1:4 are indepndent of each other. 
```{r}
tmp.tab <- table(rep(c(1:4), times=c(25,25,25,10)))
tmp.tab

chisq.test(tmp.tab)
```

*Observe*: 

* p=0.047: We can reject the null hypothesis with 95% confidence that there is no difference between the cells 
* The data in this sample suggests that the distribution of the values 1 to 4 is likely to be unequal in the *larger population*, assuming the data is randomly sampled. 

If we have a smaller sample, we would not get the same results even if the relative proportions of customers in each group are the same. Significance tests are sensitive to both the observed difference and sample size: 

```{r}
tmp.tab <-tmp.tab/5
tmp.tab

chisq.test(tmp.tab)
```
*Observe*:
 
 * The results are not significant and there is no evidence of a real difference in group sizes even though the proportion of people in group 4 is the same as in larger sample above where results were significant. 
 
That's one of the cautions about statistical significance testing: *it's dependent on sample size as well as on the real effect*

Another example, let's return to our simulated segment data (N=300 obs). 

##### Are the segment sizes significantly different from one another?

Assuming that the 300 customers are *random sample of a larger population*, we can use the chi-square test. We'll combine `chisq.test()` and `table()` into one command: 
```{r}
table(seg.df$Segment)
chisq.test(table(seg.df$Segment))
```
*Observe*

* With p=0.0006, there are significant differences in segment size
* Our sample does not support the hypothesis that there is an idenditcal number of custommers in each segment.

##### Is subscription status independent from home ownership? 

In other words, are respondents just as likely to subscribe or not subscribe,  regardless of home ownership status? Are customers just as likely to own a home or not, independent of subscription status? The null hypothesis is that home ownership and subscription status is independent i.e. that the counts in the cells are as one might expect from marginal proportions. 

There's 2 optionos for chi-square test:

1) For 2x2 contingency tables, chi-square test defaults to using *Yates' correction* which adjusts the chi-square statistic since data is not continuous (comes from a lumpy binomial distribution). To turn this off, use `correct=F` option.

2) Chi-square tests can calculate confidence intervals based on simulation, whereby it compares the observed table to thousands of simulated tables wit hteh same marginal counts. The p-value indicates the proportion of those simulations with differences between the cell counts nad marginal proportions at least as large as the ones in the observed table using the `sim=T` and `B=SIMULATIONS` arguments

```{r}
table(seg.df$subscribe, seg.df$ownHome)


# Using's Yates' correction
chisq.test(table(seg.df$subscribe, seg.df$ownHome))

# Using traditional values without Yates' correction
chisq.test(table(seg.df$subscribe, seg.df$ownHome), correct=F)

# Using simulation method of 10000 trials
chisq.test(table(seg.df$subscribe, seg.df$ownHome), sim=T, B=10000)


```
*Observe*

* Based on high p-value, we fail to reject null hypothesis and conclude that the factors are unrelated. Home ownership is independent of subscription status in our data. There is no relationship between subscriiption rate and home ownership. The factors are independent. 

### 6.3 Testing Observed Proportions: `binom.test()`

**Binomial variables** are variables that have only 2 types of values ("Y/N" "0,1"). 

For example, Chris took a walk in Manhattan and observed 12 groups of Seattle fans and 8 groups of Denver fans. Assuming the observations are a random sample of a binomial value (either Seattle or Denver fans). Is the observed value of 60% Seattle fans significantly different from equal representation (which would be 50% each)? 

We use `binom.test(successes, trials, probability)` to test what's the likelihood of randomly observing 12 groups out of 20 in one direction, if the true likelhood is 50%? 

```{r}
binom.test(12,20,p=0.5)
```
*Observe*: 

* The 95% CI is 36-81% which includes the null hypothesis value of 50% probability. 
* We conclude that observing 60% seattle fans in a sample of 20 does not conclusively demonstate that there are more Seattle fans in the larger group of fans roaming New York. 
* The p-value=0.5034 is not significant - we fail to support the idea that the results are different from the null hypothesis

####6.4.1 Interpreting Confidence Intervals

The definition of a 95% CI: *It's the range of possible sample estimates that we would expect to see 95% of the time if we repeatedly estimate the  statistic using random samples of the same sample size under the assumption that the true value in an infinite or very large population is the same as our current estimate*

It's the best guess of possible answers we would expect with repeated random sampling. 

When the CI excludes null hypothesis, the result is statistically significant. 

CI's DO NOT express our degree of confidence in our results since they don't reflect the confidence elvel in the assumptinos made. 

CI's are often misunderstood to imply that "the true value lies in the CI range" when it's the other way around "if the true value is what we obtained then we would expect additional esitmates to fall within this CI 95% of the time with random sampling."

The CI is about sample estimates, not about the true value of a population. 

Before interpreting a result, make surue it's statitically significant. If not, then the evidence for our result is weak and we should not intepret it. Best pracice is to chart the confifdence intervals when available and always report out on confidence intervals for a more complete and accurate description to stakeholders. 

`confint()` determines the CIs for a statistical model

#### What's the probability we would observe 8:12 Seattle fans out of 20, if the true rate is 50%?

Use the *density estimate* for a binomial distribution across the range of interest and sum the point probabilities:
```{r}
sum(dbinom(8:12, 20, 0.5))
```
*Observe* If we observe 20 fans and the true split is 50%, there's a 73.7% chance that would would observe between 8 to 12 fans. 


An *exact* binomial test may be too conservative (wide CI) in its estimation of CI's. Another method is to use the *[agresti-coull](http://www.stat.ufl.edu/~aa/articles/agresti_coull_1998.pdf)* method to get a slightly smaller CI but still includes 50%. Use `binom.confint(method="ac")`
```{r}
library(binom)
binom.confint(12, 20, method="ac")
```
*Observe* The CI bound using approximate (0.39 to 0.78) is smaller compared to exact binomial test (0.36 to 0.81)


##### What if we observed 120 out of 200 people to be Seattle fans? (The same proportion as before but in a larger sample)

```{r}
binom.test(120,200,.5)
```
*Observe*:

* The CI no longer includes 50%. The p-value < 0.05, indicating there is a statistically signifciant difference. 

#### Among the 20 groups, 0 groups had a mixture of Seattle and Denver fans based on their team clothing. What's the most likely proportion of groups that comprise of mixed fans?

We need to use the *Agresti-Coull* method because exact tests have no confidence intervals for 0% or 100% observations:
```{r}
binom.confint(0,20, method="ac")
```
*Observe*: The negative bound may be ignored as an artifact. We conclude that althouogh Chris observed 0 cases, the occurrence of mixed fandom groups is likely to be between 0 to 19% of the time.


The `binom` package also computes several other varients of the binomial test including a Bayesian version. 

### 6.4 T-test: Testing Group Means

A *[t-test](http://www.stat.columbia.edu/~martin/W2024/R2.pdf)* compares the mean of one sample against mean of another sample or against a specific valie i.e. 0. It compares means for exactly 2 data sets. 


#### Is the household income different among those who own a home and those who do not?

Let's check for normality before doing a t-test:
```{r fig.width=12}

# Fix the levels first

levels(seg.df$ownHome) <- c(levels(seg.df$ownHome), "ownNo")
seg.df$ownHome[is.na(seg.df$ownHome)] <- "ownNo"
summary(seg.df$ownHome)

seg.df$ownHome <- droplevels(seg.df$ownHome)
levels(seg.df$ownHome) <- c("ownYes","ownNo")
summary(seg.df$ownHome)
```

```{r fig.width=12}
par(mfrow=c(1,3))
hist(seg.df$income)
with(seg.df, hist(income[ownHome=="ownYes"]))
with(seg.df, hist(income[ownHome=="ownNo"]))

```

```{r fig.height=4}
# boxplot

#bwplot(ownHome ~ income, data=seg.df, horizontal = T, xlab="Income $", layout=c(1,2))
```
*Observe* Based on the histograms and boxplots, income is ~ normally distributed. 

Test whether home ownership overall is related to differences in income, across all segments, using `t.test(formula,data)` where `income` is the y var and `ownHome` is the x var. 

```{r}
t.test(income ~ ownHome, data=seg.df)
```
*Observe* 

*The 95% CI does not include 0, so we can conclude there is significant difference in income between home ownership. 
*The data suggests that people who own their houses have a higher income. 
*We have 95% confidence that the group difference is between \$3007 and \$12,080.
*The mean income for renters is \$47K while homeowners $55K

#### Is there a difference income between homeownrship within the Travelers segment?

We use the filter `data=subset(data, condition)` to select just Travelers and repeat the test:
```{r}
t.test(income~ ownHome, data=subset(seg.df, Segment=="Travelers"))
```
*Observe*

* The CI of -$8,508 to $11,107 include 0 which means there is not a significant difference in mean income among those Travelers in our data who own homes and who don't. 
* P-Value = 0.7916 deems not significant
* We noticed earlier that the first t-test is significant across all segments, but this test is not significant. This suggests that any significant difference must lie largely outside the "Travelers" segment

###6.5 ANOVA: Testing Multiple Group Means (vs. t-test which tests 2 groups)

ANOVA compares means of multiple groups by comparing the degree to which groups differ as measured by variance in their means from one another, relative to the variance of abervations around each mean within each group. It tests for difference among multiple means with the assumption that the groups have similar variance. 

*One-way ANOVA: Includes 1 factor
*Two-way ANOVA: Includes 2 factors

`aov(formula,data)`: basic command to set up the ANOVA model
`anova(model)`: to display standard ANOVA summary from `aov()`


##### Which factors are related to differences in mean income? Is income related to home ownership, to segment membership, or both? 

1) We run `aov(income ~ ownHome)` and assign the `aov()` model to an object so we can use it in our next step
2) `anova()` on the aov model object

```{r}
seg.aov.own <- aov(income ~ ownHome, data=seg.df)
anova(seg.aov.own)
```
*Observe*:

* There's significant variation between home ownership status and income (p-value < 0.05)

##### Is there a difference in income by segments?
```{r}

aov.inc.segments <- aov(income ~ Segment, data=seg.df)
anova(aov.inc.segments)
```
*Observe*:

* Income varies significantly by segment. 

##### If income varies by both home ownership and segment, does that mean that a more complete model should include both? 

We add both factors into the two-way ANOVA model to test this:
```{r}
anova(aov(income ~ Segment + ownHome, data=seg.df))
```
*Observe*: Results indicate that when we try to explain income differences by both Segment and home ownership, segment is a significant predictor, but not home ownership. Why? Because segment and homeownership are dependent, and the variation is captured sufficiently by segment membership alone. We can test this further using chi-square test to validate if this is true.

```{r}
table(seg.df$ownHome, seg.df$Segment)
chisq.test(table(seg.df$ownHome, seg.df$Segment))
```
*Observe* Yes, there is a significant difference between Segments and Home ownership. 

##### Could it be that home ownership is related to income in some segments but not in others?

This would be represented in our model by an *interaction effect*. In a model, 

"+" indicates vars should be modeled for main effects only.
":" model for interaction effect
"*" model for both main effect and interaction

We'll test main effects and interaction of home ownership and segment
```{r}
anova(aov(income ~ Segment * ownHome, data=seg.df))
```
*Observe* 

* Segment is a significant predictor while the rest are not. Segment membership is again the best predictor on its own. 

#### 6.5.1 Model Comparison in ANOVA

Another capability of `anova()` command is to compare 2+ models so we can analyze which model performs better in fitting the data according to RSS (Residual Sum of Squares).  NOTE: model comparison performed by `anova()` onlyl makes sense for nested models where we can perform likelihood comparisons. Other methods should be used such as the AIC and BIC criterion.

##### Which model has a better fit? ANOVA model with segment alone vs. the model with both segment + homeownership? 

```{r}
anova(aov(income ~ Segment, data=seg.df),
      aov(income ~ Segment + ownHome, data=seg.df))
```
*Observe*:

* Model 2 is not significantly different in overall fit from Model 1. 
* We fail to reject the null hypothesis of no difference in the 2nd model 

#### 6.5.2 Visualizing Group CI's 

Best practice is to visualize the results of an ANOVA by plotting confidence intervals for the group means. This tells us whether the differences are substantial in magnitude or not.  

`glht(model)` is a general linear hypothesi stest part of the `multcomp` package (multiple comparison)
```{r}
library(multcomp)
seg.aov <- aov(income ~ Segment, data=seg.df)
glht(seg.aov)
```
*Observe*: The intercept become the Moving Up segment and all results are relative to the intercept (see the positive/negative numbers)

This may be confusing to understand, so let's remove the intercept by adding "-1" to the model formula.
```{r}

seg.aov <- aov(income ~ -1 + Segment, data=seg.df)
glht(seg.aov)
```
*Observe* Mean value for each segment is provided. 
```{r}
par(mar=c(6,10,2,2))
plot(glht(seg.aov),
     xlab="Income", main="Average Income by Segment (95% CI)")
```
*Observe*: 

* The average income of Urban Hip segment is substantially lower than the other three groups
* Confidence intervals for income by segment is provided. 
* We see Urban Hip segment has a larger CI than other segments. Suburb Mix has a smaller CI. 

####6.5.3 Stepwise Modeling: Variable Selection for ANOVA

With stepwise modeling, we can aotmate the iterative process of bulding models by adding/removing variables from the model based on some threshold/improvement criterion. 

* Backward stepwise: starting with a larger set of vars and progressing cutting them. This is the default direction of `step()`
* Forward stepwise: adding variables

`step()` uses the AIC to compare models on the basis of overall fit and model complexity. Use `response ~ .` to model all main effects in the model where "." is short for "all other variables except the response var. By default, this model tests all main effects without interactions. To test higher order effects (i.e. quadratic), use superscript notation i.e. "`.^2`" for two-way interactions, but it's usually good to avoid such interaction modeling. 

```{r}
seg.aov.step <- step(aov(income ~., data=seg.df))
```
*Observe* Stepwise modeling included all 6 vars at first, went through several steps of removing vars, and concluded with the "best" model as `income ~ Segment`.

We can exampine the result of stepwise modeling using `anova()` on the model object
```{r}
anova(seg.aov.step)
```

In cases where there's dozens, hundreds or thousands of vars, it's better to use other procedures like lasso, random forect, or a machine learning algorithm (SGD, Decision Trees, Regression etc.)

### 6.6 Bayesian ANOVA